# -*- coding: utf-8 -*-
"""FP_DM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tgnXevxANjCr6x3oP3WOmJNWeAFPGuvC
"""

import pandas as pd
df = pd.read_csv('/diabetes_012_health_indicators_BRFSS2015.csv')

print(df.columns)
print(df.head)

"""## **Evaluasi dengan Semua Fitur Dataset**
# Tanpa Penghapusan Outlier
Evaluasi menggunakan Logistic Regression dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# Memisahkan fitur dan target
X = df.drop('Diabetes_012', axis=1)
y = df['Diabetes_012']

# Membagi data menjadi set pelatihan dan set pengujian
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Visualisasi distribusi sebelum sampling
plt.figure(figsize=(12, 6))

plt.subplot(1, 3, 1)
y_train.value_counts().plot(kind='bar')
plt.title('Distribusi Sebelum Sampling')
plt.xlabel('Kelas')
plt.ylabel('Jumlah')

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Visualisasi distribusi setelah SMOTE
plt.subplot(1, 3, 2)
pd.Series(y_train_smote).value_counts().plot(kind='bar')
plt.title('Distribusi Setelah Oversampling (SMOTE)')
plt.xlabel('Kelas')
plt.ylabel('Jumlah')

# Undersampling menggunakan RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Visualisasi distribusi setelah RandomUnderSampler
plt.subplot(1, 3, 3)
pd.Series(y_train_rus).value_counts().plot(kind='bar')
plt.title('Distribusi Setelah Undersampling (RandomUnderSampler)')
plt.xlabel('Kelas')
plt.ylabel('Jumlah')

plt.tight_layout()
plt.show()

# Melatih model Logistic Regression dengan data oversampled
model_smote = LogisticRegression(random_state=42, max_iter=5000, solver='saga', tol=1e-3)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled
print("Evaluasi model dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_smote))

# Melatih model Logistic Regression dengan data undersampled
model_rus = LogisticRegression(random_state=42, max_iter=5000, solver='saga', tol=1e-3)
model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled
print("Evaluasi model dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus))

"""Evaluasi menggunakan Gradient Boost dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)


"""

from sklearn.ensemble import GradientBoostingClassifier

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Undersampling menggunakan RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Melatih model Gradient Boosting dengan data oversampled
model_smote = GradientBoostingClassifier(random_state=42)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled
print("Evaluasi model dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_smote, zero_division=1))

# Melatih model Gradient Boosting dengan data undersampled
model_rus = GradientBoostingClassifier(random_state=42)
model_rus.fit(X_train_rus, y_train_rus,)

# Memprediksi pada set pengujian
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled
print("Evaluasi model dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus, zero_division=1))

"""Evaluasi menggunakan Decision Tree dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

from sklearn.tree import DecisionTreeClassifier

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Undersampling menggunakan RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Melatih model Decision Tree dengan data oversampled
model_smote = DecisionTreeClassifier(random_state=42)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled
print("Evaluasi model dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_smote, zero_division=1))

# Melatih model Decision Tree dengan data undersampled
model_rus = DecisionTreeClassifier(random_state=42)
model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled
print("Evaluasi model dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus, zero_division=1))

"""# Penghapusan Outlier
Evaluasi menggunakan Logistic Regression dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)

Pengecekan dan Penghapusan Outlier dengan Z-Score
"""

import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Memisahkan fitur dan target
X = df.drop('Diabetes_012', axis=1)
y = df['Diabetes_012']

# Menggabungkan kembali untuk keperluan outlier detection
data = pd.concat([X, y], axis=1)

# Mengecek ukuran dataset sebelum penghapusan outlier
print("Ukuran dataset sebelum penghapusan outlier:", data.shape)

# Menghitung Z-score
z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))
threshold = 3  # threshold umum untuk z-score
outliers = np.where(z_scores > threshold)

# Menghitung jumlah outlier
num_outliers = len(np.unique(outliers[0]))
print("Jumlah outlier yang ditemukan:", num_outliers)

# Menghapus outlier
data_cleaned = data[(z_scores < threshold).all(axis=1)]

# Mengecek ukuran dataset setelah penghapusan outlier
print("Ukuran dataset setelah penghapusan outlier:", data_cleaned.shape)

# Visualisasi distribusi kelas sebelum dan sesudah penghapusan outlier
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
data.boxplot(rot=90)
plt.title('Distribusi Sebelum Penghapusan Outlier')

plt.subplot(1, 2, 2)
data_cleaned.boxplot(rot=90)
plt.title('Distribusi Setelah Penghapusan Outlier')

plt.tight_layout()
plt.show()

# Memisahkan fitur dan target dari dataset yang sudah dibersihkan
X_cleaned = data_cleaned.drop('Diabetes_012', axis=1)
y_cleaned = data_cleaned['Diabetes_012']

"""# Sesudah Penghapusan Outlier
Evaluasi menggunakan Logistic Regression dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)
"""

# Membagi data menjadi set pelatihan dan set pengujian
X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.3, random_state=42, stratify=y_cleaned)

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Undersampling menggunakan RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Melatih model Logistic Regression dengan data oversampled
model_smote = LogisticRegression(random_state=42, max_iter=5000, solver='saga', tol=1e-3)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled
print("Evaluasi model Logistic Regression dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_smote, zero_division=1))

# Melatih model Logistic Regression dengan data undersampled
model_rus = LogisticRegression(random_state=42, max_iter=5000, solver='saga', tol=1e-3)
model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled
print("Evaluasi model Logistic Regression dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus, zero_division=1))

"""Evaluasi menggunakan Gradient Boost dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

# Melatih model Gradient Boosting dengan data oversampled
model_smote = GradientBoostingClassifier(random_state=42)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled
print("Evaluasi model Gradient Boosting dengan oversampling (SMOTE):")
print(confusion_matrix(y_test, y_pred_smote))
print(classification_report(y_test, y_pred_smote, zero_division=1))

# Melatih model Gradient Boosting dengan data undersampled
model_rus = GradientBoostingClassifier(random_state=42)
model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled
print("Evaluasi model Gradient Boosting dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus, zero_division=1))

"""Evaluasi menggunakan Decision Tree dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

# Melatih model Decision Tree dengan data oversampled
model_smote = DecisionTreeClassifier(random_state=42)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled
print("Evaluasi model Decision Tree dengan oversampling (SMOTE):")
print(confusion_matrix(y_test, y_pred_smote))
print(classification_report(y_test, y_pred_smote, zero_division=1))

# Melatih model Decision Tree dengan data undersampled
model_rus = DecisionTreeClassifier(random_state=42)
model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled
print("Evaluasi model Decision Tree dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus, zero_division=1))

"""## **Evaluasi dengan Seleksi Fitur**
# Seleksi Fitur
# Seleksi Fitur tanpa Penghapusan Outlier
Seleksi fitur menggunakan metode RFE (Recursive Feature Selection)
"""

from sklearn.feature_selection import RFE
import seaborn as sns

# Memisahkan fitur dan target
X = df.drop('Diabetes_012', axis=1)
y = df['Diabetes_012']

# Menggabungkan kembali untuk keperluan outlier detection
data = pd.concat([X, y], axis=1)

# Menghitung Z-score
z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))
threshold = 3  # threshold umum untuk z-score
outliers = np.where(z_scores > threshold)

# Menghapus outlier
data_cleaned = data[(z_scores < threshold).all(axis=1)]

# Memisahkan fitur dan target dari dataset yang sudah dibersihkan
X_cleaned = data_cleaned.drop('Diabetes_012', axis=1)
y_cleaned = data_cleaned['Diabetes_012']

# Menggunakan RFE dengan Logistic Regression untuk seleksi fitur
model = LogisticRegression(max_iter=5000, solver='saga', tol=1e-3)
rfe = RFE(model, n_features_to_select=10)  # Misal, kita ingin memilih 10 fitur terbaik
fit = rfe.fit(X_cleaned, y_cleaned)

# Menampilkan fitur yang dipilih
selected_features = X_cleaned.columns[fit.support_]
print("Fitur yang dipilih oleh RFE:")
print(selected_features)

# Dataset dengan fitur yang dipilih
X_selected = X_cleaned[selected_features]

# Menampilkan fitur sebelum seleksi
print("\nFitur sebelum seleksi:")
print(X_cleaned.columns)

# Visualisasi perubahan fitur dengan heatmap
plt.figure(figsize=(10, 6))
plt.title('Heatmap Korelasi Fitur Sebelum dan Setelah Seleksi')
sns.heatmap(X_cleaned.corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.show()

"""# Setelah Seleksi Fitur Tanpa Penghapusan Outlier

Evaluasi menggunakan Logistic Regression dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)
"""

# Membagi data menjadi set pelatihan dan set pengujian
X_train, X_test, y_train, y_test = train_test_split(X_selected, y_cleaned, test_size=0.3, random_state=42, stratify=y_cleaned)

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Undersampling menggunakan RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Melatih model Logistic Regression dengan data oversampled (SMOTE)
model_smote = LogisticRegression(random_state=42, max_iter=5000, solver='saga', tol=1e-3)
model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian dengan data oversampled (SMOTE)
y_pred_smote = model_smote.predict(X_test)

# Evaluasi model dengan data oversampled (SMOTE)
print("Evaluasi model Logistic Regression dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_smote, zero_division=1))

# Melatih model Logistic Regression dengan data undersampled (RandomUnderSampler)
model_rus = LogisticRegression(random_state=42, max_iter=5000, solver='saga', tol=1e-3)
model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian dengan data undersampled (RandomUnderSampler)
y_pred_rus = model_rus.predict(X_test)

# Evaluasi model dengan data undersampled (RandomUnderSampler)
print("Evaluasi model Logistic Regression dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_rus, zero_division=1))

"""Evaluasi menggunakan Gradient Boost dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

from sklearn.ensemble import GradientBoostingClassifier

# Inisialisasi model Gradient Boosting
gb_model_smote = GradientBoostingClassifier(random_state=42)

# Melatih model dengan data oversampled (SMOTE)
gb_model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian dengan data oversampled (SMOTE)
y_pred_gb_smote = gb_model_smote.predict(X_test)

# Evaluasi model dengan data oversampled (SMOTE)
print("Evaluasi model Gradient Boosting dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_gb_smote, zero_division=1))

# Inisialisasi model Gradient Boosting untuk undersampled data (RandomUnderSampler)
gb_model_rus = GradientBoostingClassifier(random_state=42)

# Melatih model dengan data undersampled (RandomUnderSampler)
gb_model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian dengan data undersampled (RandomUnderSampler)
y_pred_gb_rus = gb_model_rus.predict(X_test)

# Evaluasi model dengan data undersampled (RandomUnderSampler)
print("Evaluasi model Gradient Boosting dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_gb_rus, zero_division=1))

"""Evaluasi menggunakan Decision Tree dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

from sklearn.tree import DecisionTreeClassifier

# Inisialisasi model Decision Tree
dt_model_smote = DecisionTreeClassifier(random_state=42)

# Melatih model dengan data oversampled (SMOTE)
dt_model_smote.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian dengan data oversampled (SMOTE)
y_pred_dt_smote = dt_model_smote.predict(X_test)

# Evaluasi model dengan data oversampled (SMOTE)
print("Evaluasi model Decision Tree dengan oversampling (SMOTE):")
print(classification_report(y_test, y_pred_dt_smote, zero_division=1))

# Inisialisasi model Decision Tree untuk undersampled data (RandomUnderSampler)
dt_model_rus = DecisionTreeClassifier(random_state=42)

# Melatih model dengan data undersampled (RandomUnderSampler)
dt_model_rus.fit(X_train_rus, y_train_rus)

# Memprediksi pada set pengujian dengan data undersampled (RandomUnderSampler)
y_pred_dt_rus = dt_model_rus.predict(X_test)

# Evaluasi model dengan data undersampled (RandomUnderSampler)
print("Evaluasi model Decision Tree dengan undersampling (RandomUnderSampler):")
print(classification_report(y_test, y_pred_dt_rus, zero_division=1))

"""# Evaluasi dengan Seleksi Fitur dan Penghapusan Outlier
# Penghapusan Outlier
"""

# Memisahkan fitur dan target
X = df.drop('Diabetes_012', axis=1)
y = df['Diabetes_012']

# Menggabungkan kembali untuk keperluan outlier detection
data = pd.concat([X, y], axis=1)

# Mengecek ukuran dataset sebelum penghapusan outlier
print("Ukuran dataset sebelum penghapusan outlier:", data.shape)

# Menghitung Z-score
z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))
threshold = 3  # threshold umum untuk z-score
outliers = np.where(z_scores > threshold)

# Menghitung jumlah outlier
num_outliers = len(np.unique(outliers[0]))
print("Jumlah outlier yang ditemukan:", num_outliers)

# Menghapus outlier
data_cleaned = data[(z_scores < threshold).all(axis=1)]

# Mengecek ukuran dataset setelah penghapusan outlier
print("Ukuran dataset setelah penghapusan outlier:", data_cleaned.shape)

# Visualisasi distribusi fitur sebelum dan sesudah penghapusan outlier menggunakan boxplot
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
data.boxplot(rot=90)
plt.title('Distribusi Sebelum Penghapusan Outlier')

plt.subplot(1, 2, 2)
data_cleaned.boxplot(rot=90)
plt.title('Distribusi Setelah Penghapusan Outlier')

plt.tight_layout()
plt.show()

# Memisahkan fitur dan target dari dataset yang sudah dibersihkan
X_cleaned = data_cleaned.drop('Diabetes_012', axis=1)
y_cleaned = data_cleaned['Diabetes_012']

"""# Seleksi Fitur dengan RFE Setelah Penghapusan Outlier"""

# Menggunakan RFE dengan Logistic Regression untuk seleksi fitur
model = LogisticRegression(max_iter=5000, solver='saga', tol=1e-3)
rfe = RFE(model, n_features_to_select=8)  # Misal, kita ingin memilih 10 fitur terbaik
fit = rfe.fit(X_cleaned, y_cleaned)

# Menampilkan fitur yang dipilih
selected_features = X_cleaned.columns[fit.support_]
print("Fitur yang dipilih oleh RFE setelah penghapusan outlier:")
print(selected_features)

# Dataset dengan fitur yang dipilih
X_selected = X_cleaned[selected_features]

# Menampilkan fitur sebelum seleksi
print("\nFitur sebelum seleksi:")
print(X_cleaned.columns)

"""Evaluasi menggunakan Logistic Regression dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

# Membagi data menjadi set pelatihan dan set pengujian
X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.3, random_state=42, stratify=y_cleaned)

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Undersampling menggunakan RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Inisialisasi model Logistic Regression
logreg_model = LogisticRegression(max_iter=5000, solver='saga', tol=1e-3)

# Melatih model Logistic Regression dengan data oversampled (SMOTE)
logreg_model.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian dengan data oversampled (SMOTE)
y_pred_logreg_smote = logreg_model.predict(X_test)

# Evaluasi model Logistic Regression dengan data oversampled (SMOTE)
print("Evaluasi model Logistic Regression dengan oversampling (SMOTE) setelah penghapusan outlier:")
print(classification_report(y_test, y_pred_logreg_smote, zero_division=1))

"""Evaluasi menggunakan Gradient Boost dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Inisialisasi model Gradient Boosting
gb_model = GradientBoostingClassifier(random_state=42)

# Melatih model Gradient Boosting dengan data oversampled (SMOTE)
gb_model.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian dengan data oversampled (SMOTE)
y_pred_gb_smote = gb_model.predict(X_test)

# Evaluasi model Gradient Boosting dengan data oversampled (SMOTE)
print("Evaluasi model Gradient Boosting dengan oversampling (SMOTE) setelah penghapusan outlier:")
print(classification_report(y_test, y_pred_gb_smote, zero_division=1))

"""Evaluasi menggunakan Decision Tree dengan Oversampling (SMOTE) dan Undersampling (RandomUnderSampler)"""

# Oversampling menggunakan SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Inisialisasi model Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)

# Melatih model Decision Tree dengan data oversampled (SMOTE)
dt_model.fit(X_train_smote, y_train_smote)

# Memprediksi pada set pengujian dengan data oversampled (SMOTE)
y_pred_dt_smote = dt_model.predict(X_test)

# Evaluasi model Decision Tree dengan data oversampled (SMOTE)
print("Evaluasi model Decision Tree dengan oversampling (SMOTE) setelah penghapusan outlier:")
print(classification_report(y_test, y_pred_dt_smote, zero_division=1))